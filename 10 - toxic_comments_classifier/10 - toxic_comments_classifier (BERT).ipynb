{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Предподготовка\" data-toc-modified-id=\"Предподготовка-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Предподготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Вывод</a></span></li><li><span><a href=\"#Токенизация-текстов\" data-toc-modified-id=\"Токенизация-текстов-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Токенизация текстов</a></span></li><li><span><a href=\"#Создание-эмбеддинга\" data-toc-modified-id=\"Создание-эмбеддинга-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Создание эмбеддинга</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Дерево-решений\" data-toc-modified-id=\"Дерево-решений-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Дерево решений</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Линейная-регрессия\" data-toc-modified-id=\"Линейная-регрессия-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Линейная регрессия</a></span></li><li><span><a href=\"#LGBM\" data-toc-modified-id=\"LGBM-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>LGBM</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Тестирование</a></span><ul class=\"toc-item\"><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "import re\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from pymystem3 import Mystem\n",
    "import matplotlib as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from transformers import BertTokenizer\n",
    "from transformers import AutoModel\n",
    "\n",
    "# цвет текста\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RS = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    data = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=0.2, random_state=RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31914 entries, 146790 to 139386\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    31914 non-null  object\n",
      " 1   toxic   31914 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 748.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146790</th>\n",
       "      <td>Ahh shut the fuck up you douchebag sand nigger...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>\"\\n\\nREPLY: There is no such thing as Texas Co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115087</th>\n",
       "      <td>Reply\\nHey, you could at least mention Jasenov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48830</th>\n",
       "      <td>Thats fine, there is no deadline )   chi?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136034</th>\n",
       "      <td>\"\\n\\nDYK nomination of Mustarabim\\n Hello! You...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "146790  Ahh shut the fuck up you douchebag sand nigger...      1\n",
       "2941    \"\\n\\nREPLY: There is no such thing as Texas Co...      0\n",
       "115087  Reply\\nHey, you could at least mention Jasenov...      0\n",
       "48830           Thats fine, there is no deadline )   chi?      0\n",
       "136034  \"\\n\\nDYK nomination of Mustarabim\\n Hello! You...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    31914.000000\n",
       "mean       389.017923\n",
       "std        574.252295\n",
       "min          6.000000\n",
       "25%         95.000000\n",
       "50%        204.000000\n",
       "75%        436.000000\n",
       "max       5000.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# описание данных по длине строк\n",
    "data['text'].str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1000.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# оценка выбросов\n",
    "ax = data['text'].apply(len).plot(kind='box')\n",
    "ax.set_ylim(0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.03"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# процент потерянных данных\n",
    "round(len(data['text'].str.len().loc[data['text'].str.len() > (600)]) * 100 / len(data['text']), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# дубликаты в данных\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "Максимальная длина текста 5000 символов, что безусловно является выбросом, в свою очередь медиана 205 символов. \n",
    "Поступим следующим образом: т.к. нам предстоит делать токенизацию с помощью BERT мы удалим все значения более 600 символов. Потери составят 17% от данных. Это не критично, т.к. данных для обучения очень много.\n",
    "\n",
    "Имеем сильный дисбаланс классов. В идеале хотелось бы использовать метод upsample (увеличение количества 1), но боюсь что токенизация может занять очень много времени поэтому решено использовать метод downsample (уменьшение количества 0). Если результаты по времени будут удовлетворительными, а точность f1 будет достаточной для принятия задания. Попробую метод upsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Предподготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим выбросы\n",
    "data = data.loc[data['text'].str.len() <= 600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146790</th>\n",
       "      <td>Ahh shut the fuck up you douchebag sand nigger...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>\"\\n\\nREPLY: There is no such thing as Texas Co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115087</th>\n",
       "      <td>Reply\\nHey, you could at least mention Jasenov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48830</th>\n",
       "      <td>Thats fine, there is no deadline )   chi?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136034</th>\n",
       "      <td>\"\\n\\nDYK nomination of Mustarabim\\n Hello! You...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "146790  Ahh shut the fuck up you douchebag sand nigger...      1\n",
       "2941    \"\\n\\nREPLY: There is no such thing as Texas Co...      0\n",
       "115087  Reply\\nHey, you could at least mention Jasenov...      0\n",
       "48830           Thats fine, there is no deadline )   chi?      0\n",
       "136034  \"\\n\\nDYK nomination of Mustarabim\\n Hello! You...      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # удаление цифр и пунктуации, кроме апострофа\n",
    "    text = re.sub(\"[^a-zA-Z']\", \" \", text)\n",
    "    \n",
    "    # циклом пройдёмся дважды по тексту, чтобы гарантированно удалить одинокостоящие символы\n",
    "    for _ in range(2):\n",
    "        # удаление одинокостоящих символов\n",
    "        text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
    "    \n",
    "        # удаление множественных пробелов\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress bar!: 100%|██████████| 26478/26478 [00:01<00:00, 18656.53it/s]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tqdm.pandas(desc=\"progress bar!\")\n",
    "\n",
    "data['text'] = data['text'].progress_apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146790</th>\n",
       "      <td>Ahh shut the fuck up you douchebag sand nigger...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>REPLY There is no such thing as Texas Commerc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115087</th>\n",
       "      <td>Reply Hey you could at least mention Jasenovac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48830</th>\n",
       "      <td>Thats fine there is no deadline chi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136034</th>\n",
       "      <td>DYK nomination of Mustarabim Hello Your submi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "146790  Ahh shut the fuck up you douchebag sand nigger...      1\n",
       "2941     REPLY There is no such thing as Texas Commerc...      0\n",
       "115087  Reply Hey you could at least mention Jasenovac...      0\n",
       "48830                Thats fine there is no deadline chi       0\n",
       "136034   DYK nomination of Mustarabim Hello Your submi...      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# уменьшение выборки\n",
    "def downsample_after_emb(X, y, fraction):\n",
    "    y_zeros = y[y == 0]\n",
    "    y_ones = y[y == 1]\n",
    "    \n",
    "    X_zeros = X[y_zeros.index]\n",
    "    X_ones = X[y_ones.index]\n",
    "    \n",
    "\n",
    "    X_downsampled = np.concatenate([X_zeros[:int((X_zeros.shape[0]) * fraction)], X_ones])\n",
    "    \n",
    "    y_downsampled = pd.concat([y_zeros[:int((y_zeros.shape[0]) * fraction)], y_ones])\n",
    "    \n",
    "    X_downsampled, y_downsampled = shuffle(\n",
    "        X_downsampled, y_downsampled, random_state=RS)\n",
    "\n",
    "    return X_downsampled, y_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "Данные обработаны:\n",
    "\n",
    "* Уменьшилась максимальная длина одной строки до `584`.\n",
    "* Средняя и медиана равны  `167` и `126` соответственно.\n",
    "* Текст очищен от лишних символов\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = BertTokenizer.from_pretrained('unitary/toxic-bert')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "encode_dict = tokenizer.batch_encode_plus(\n",
    "                        data['text'],                      \n",
    "                        add_special_tokens = True,    \n",
    "                        max_length = 256,      \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   \n",
    "                        return_tensors = 'pt',    \n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = encode_dict['input_ids']\n",
    "attention_mask = encode_dict['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание эмбеддинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('unitary/toxic-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af7990be04048fc9ba103e9e414ef4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Количество батчей: 1\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 2\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 3\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 4\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 5\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 6\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 7\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 8\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 9\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 10\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 11\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 12\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 13\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 14\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 15\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 16\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 17\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 18\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 19\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 20\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 21\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 22\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 23\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 24\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 25\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 26\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 27\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 28\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 29\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 30\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 31\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 32\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 33\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 34\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 35\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 36\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 37\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 38\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 39\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 40\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 41\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 42\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 43\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 44\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 45\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 46\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 47\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 48\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 49\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 50\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 51\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 52\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 53\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 54\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 55\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 56\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 57\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 58\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 59\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 60\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 61\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 62\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 63\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 64\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 65\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 66\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 67\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 68\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 69\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 70\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 71\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 72\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 73\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 74\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 75\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Количество батчей: 76\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 77\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 78\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 79\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 80\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 81\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 82\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 83\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 84\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 85\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 86\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 87\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 88\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 89\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 90\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 91\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 92\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 93\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 94\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 95\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 96\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 97\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 98\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 99\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 100\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 101\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 102\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 103\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 104\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 105\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 106\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 107\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 108\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 109\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 110\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 111\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 112\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 113\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 114\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 115\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 116\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 117\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 118\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 119\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 120\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 121\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 122\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 123\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 124\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 125\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 126\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 127\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 128\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 129\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 130\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 131\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "\n",
      "    Количество батчей: 132\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "embeddings = []\n",
    "\n",
    "for batch_number in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    start = batch_size*batch_number\n",
    "    end = batch_size*(batch_number + 1)\n",
    "    batch = torch.LongTensor(padded[start:end]) \n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[start:end])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "\n",
    "    np.savez(\"embeddings_for_toxic_comments\", *embeddings)\n",
    "\n",
    "    print('''\n",
    "    Количество батчей: {0}\n",
    "    Количество текстов в одном батче: {1}\n",
    "    Длина эмбеддинга одного текста: {2}\\n'''.format(len(embeddings),\n",
    "                                                  len(embeddings[0]),\n",
    "                                                  len(embeddings[0][0])\n",
    "                                                  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем файл локально, т.к. создание эмбеддингов заняло 2,5 часа. Результаты:\n",
    "\n",
    "* Количество батчей: 132\n",
    "* Количество текстов в одном батче: 200\n",
    "* Длина эмбеддинга одного текста: 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_zip = np.load('embeddings_for_toxic_comments.npz') \n",
    "embeddings = []\n",
    "for key, value in embeddings_zip.items():\n",
    "    embeddings.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разделение выборки и балансировка классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "target = data['toxic']\n",
    "target = target.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26400, 768), (26478,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target[:features.shape[0]], \n",
    "                                                                            shuffle=False, random_state=RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, target_train = downsample_after_emb(features_train, target_train, 0.13)\n",
    "target_train.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "* Был устранён дисбаланс классов методом downsamples.\n",
    "\n",
    "* Текст был токенизирован и на его основе создан эмбеддинг.\n",
    "\n",
    "* Выборки разбиты для дальнейшего обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_params(model, params, scoring, features, target):\n",
    "    '''    \n",
    "    Input: --> learning algoritm, model parametrs --> dict, scoring method --> str, pd.DataFrame, pd.Series\n",
    "    Output --> learning algoritm, model_grid.best_params_ --> dict, model_grid.best_score_\n",
    "    Process: 1. Задаём параметры GridSearchCV\n",
    "             2. Обучаем модель\n",
    "             3. Сохраняем лучшие параметры и лучший показатель метрики\n",
    "    '''        \n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=RS)\n",
    "    \n",
    "    model_grid = GridSearchCV(model, params,\n",
    "                              n_jobs=-1, cv=kf, scoring=scoring)\n",
    "    model_grid.fit(features, target)\n",
    "    best_params = model_grid.best_params_\n",
    "    best_score = model_grid.best_score_\n",
    "    \n",
    "    display(model_grid)\n",
    "    display(best_params)\n",
    "    display(HTML(f'<font color=\"red\"> Лучший результат F1:{best_score}</font>'))\n",
    "    return model_grid, best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = pd.DataFrame(index=['f1_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "        'tc': DecisionTreeClassifier(),\n",
    "        'lr': LogisticRegression(random_state=RS),\n",
    "        'rf': RandomForestClassifier(),\n",
    "        'lgbm': LGBMClassifier()\n",
    "    } \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = models_dict.get('tc')\n",
    "tree_params = {'max_depth': range(3),\n",
    "              'random_state':[RS]}\n",
    "\n",
    "start = timer()\n",
    "model_best_tree, best_params_tree , best_score_tree = grid_params(tree_model, tree_params, 'f1', features_train, target_train)\n",
    "end = timer()\n",
    "\n",
    "results_train[type(tree_model).__name__] = [best_score_tree]\n",
    "\n",
    "timetrain = round((end - start), 2)\n",
    "print(timetrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = models_dict.get('rf')\n",
    "forest_params = {'max_depth': range(4),\n",
    "                'n_estimators': range(130)\n",
    "                'random_state':[RS]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "model_best_forest, best_params_forest , best_score_forest = grid_params(forest_model, forest_params, 'f1', features_train, target_train)\n",
    "end = timer()\n",
    "\n",
    "timetrain = round((end - start), 2)\n",
    "print(timetrain)\n",
    "\n",
    "results_train[type(forest_model).__name__] = [best_score_forest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font color=\"red\"> Лучший результат F1:0.973783201161095</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.48\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "cv_sc_linReg = cross_val_score(models_dict.get('lr'),\n",
    "                                        features_train,\n",
    "                                        target_train,\n",
    "                                        cv=5, scoring='f1').mean()\n",
    "end = timer()\n",
    "timetrain = round((end - start), 2)\n",
    "display(HTML(f'<font color=\"red\"> Лучший результат F1:{cv_sc_linReg}</font>'))\n",
    "print(timetrain)\n",
    "\n",
    "results_train[type(models_dict.get('lr')).__name__] = [cv_sc_linReg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = models_dict.get('lgbm')\n",
    "lgbm_params = {'max_depth': range(4),\n",
    "                   'objective': ['regression'],\n",
    "                   \"metric\": ['rmse'],\n",
    "                   'n_estimators': range(500, 650, 50),\n",
    "                   'learning_rate':np.arange(0.012, 0.017, 0.001),\n",
    "                    \"verbosity\": [1],\n",
    "                   'random_state': [RS],\n",
    "                   \"boosting_type\": ['gbdt']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "model_best_lgbm, best_params_lgbm , best_score_lgbm = grid_params(lgbm_model , lgbm_params, 'f1', features_train, target_train)\n",
    "end = timer()\n",
    "\n",
    "timetrain = round((end - start), 2)\n",
    "print(timetrain)\n",
    "\n",
    "results_train[type(lgbm_model).__name__] = [best_score_lgbm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "Точность моделей `RandomForestClassifier`, `LogisticRegression`, `LGBMClassifier` > 0.97. `DecisionTreeClassifier` =0.96.\n",
    "\n",
    "В целом можем использовать любую модель для дальнейшего обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = pd.DataFrame(index=['f1_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model_name):\n",
    "    \n",
    "    best_model_dict = {\n",
    "        'tc': model_best_tree,\n",
    "        'lr': LogisticRegression(random_state=RS),\n",
    "        'rf': model_best_forest,\n",
    "        'lgbm': model_best_lgbm\n",
    "    }\n",
    "    \n",
    "    \n",
    "    if model_name == 'lr':\n",
    "            \n",
    "        model = LogisticRegression(random_state=RS)\n",
    "        model.fit(features_train, target_train)\n",
    "        predicts = model.predict(features_test)\n",
    "        f1_score_result = f1_score(target_test, predicts)\n",
    "        results_test[model_name] = [f1_score_result]\n",
    "            \n",
    "    else:\n",
    "          predict = best_model_dict.get(model_name).predict(features_test)\n",
    "           \n",
    "          f1_score_result = f1_score(target_test, predict)\n",
    "    \n",
    "          results_test[model_name] = [f1_score_result]\n",
    "    \n",
    "     \n",
    "    \n",
    "    \n",
    "    print(f1_score_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test('tc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8684895833333333\n"
     ]
    }
   ],
   "source": [
    "test('lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test('lgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_test</th>\n",
       "      <td>0.86849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lr\n",
       "f1_test  0.86849"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "В результате исследования значение f1 на всех моделях > `0.95`. Лучший результат показала `линейная регрессия` с результатом `0.868`.\n",
    "\n",
    "Результаты с использованием модели BERT. Основным наблюдением хотел бы отметить для себя то что bert создаёт эмбеддинг очень долго и это заставляет задуматься об использовании дополнительных ресурсов для выстраивания пайплайна обучения моделей."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 473,
    "start_time": "2022-06-23T13:27:40.148Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.623Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.624Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.625Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.626Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.627Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.628Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.629Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.630Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.631Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.632Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.633Z"
   },
   {
    "duration": 1,
    "start_time": "2022-06-23T13:27:40.634Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.635Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.636Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.637Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.652Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.654Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.655Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.656Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.657Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.658Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.659Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.660Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.661Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.662Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.663Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.665Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.666Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T13:27:40.667Z"
   },
   {
    "duration": 88965,
    "start_time": "2022-06-23T13:27:56.471Z"
   },
   {
    "duration": 2349,
    "start_time": "2022-06-23T14:00:23.324Z"
   },
   {
    "duration": 31,
    "start_time": "2022-06-23T14:00:26.706Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-23T14:00:27.340Z"
   },
   {
    "duration": 112,
    "start_time": "2022-06-23T14:00:27.595Z"
   },
   {
    "duration": 449,
    "start_time": "2022-06-23T14:00:27.791Z"
   },
   {
    "duration": 166,
    "start_time": "2022-06-23T14:00:28.241Z"
   },
   {
    "duration": 207,
    "start_time": "2022-06-23T14:00:28.453Z"
   },
   {
    "duration": 79,
    "start_time": "2022-06-23T14:00:30.917Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-23T14:00:32.006Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-23T14:00:33.487Z"
   },
   {
    "duration": 6055,
    "start_time": "2022-06-23T14:00:34.558Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-23T14:00:41.570Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-23T14:00:42.234Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-23T14:00:43.035Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-23T14:00:43.755Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-23T14:00:44.212Z"
   },
   {
    "duration": 120,
    "start_time": "2022-06-23T14:00:47.325Z"
   },
   {
    "duration": 144,
    "start_time": "2022-06-23T14:00:48.077Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-23T14:00:48.999Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-23T14:00:51.544Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-23T14:00:52.592Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-23T14:01:01.388Z"
   },
   {
    "duration": 6828,
    "start_time": "2022-06-23T14:01:02.062Z"
   },
   {
    "duration": 258,
    "start_time": "2022-06-23T14:01:16.822Z"
   },
   {
    "duration": 1749,
    "start_time": "2022-06-23T14:01:36.889Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-23T14:01:46.836Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-23T14:01:52.145Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-23T14:01:59.549Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-23T14:02:12.231Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-23T14:02:27.561Z"
   },
   {
    "duration": 1349,
    "start_time": "2022-06-23T14:02:41.307Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-23T14:02:47.611Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-23T14:02:54.007Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-23T14:03:07.617Z"
   },
   {
    "duration": 24,
    "start_time": "2022-06-23T14:03:15.417Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-23T14:03:17.838Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-23T14:03:40.956Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-23T14:03:49.654Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-23T14:04:15.185Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-23T14:04:19.514Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-23T14:10:25.809Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-23T14:10:29.463Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-23T14:10:39.277Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-23T14:10:44.990Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-23T14:10:51.491Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-23T14:10:58.358Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-23T14:11:22.615Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-23T14:11:36.820Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-23T14:11:43.485Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-23T14:11:47.699Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-23T14:12:51.028Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-23T14:13:38.557Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-23T14:14:34.876Z"
   },
   {
    "duration": 32005,
    "start_time": "2022-06-23T14:14:37.361Z"
   },
   {
    "duration": 31022,
    "start_time": "2022-06-23T14:15:36.427Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-23T14:16:20.094Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-23T14:16:45.378Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.389px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
