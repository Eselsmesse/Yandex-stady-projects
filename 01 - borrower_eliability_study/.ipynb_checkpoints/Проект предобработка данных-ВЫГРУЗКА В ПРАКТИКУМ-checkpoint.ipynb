{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Исследование надёжности заёмщиков\n",
    "\n",
    "Заказчик — кредитный отдел банка. Нужно разобраться, влияет ли семейное положение и количество детей клиента на факт погашения кредита в срок. Входные данные от банка — статистика о платёжеспособности клиентов.\n",
    "\n",
    "Результаты исследования будут учтены при построении модели **кредитного скоринга** — специальной системы, которая оценивает способность потенциального заёмщика вернуть кредит банку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1. Откройте файл с данными и изучите общую информацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datasets/data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-435a2503d9f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/datasets/data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datasets/data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('/datasets/data.csv')\n",
    "\n",
    "\n",
    "data.info() #общая информация о таблице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['family_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['family_status_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все виды семейного статуса соответствуют своему type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.sort_values(by='days_employed', ascending=True) #визуально оцениваем данные о количестве отработанных дней"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметки:\n",
    "1) В столбец days_employed очень проблемный выгружены данные с отрицательным значениям в днях, природа ошибки не понятна, так как имеются значения  со знаками плюс и минус. Так же в столбце имеются имеются нереалистичные 6-ти значные. Имеются прпущенные значения обозначающие что человек является безработным\n",
    "\n",
    "2) Значения в сталбцах family_status и family_status_id соответствуют друг другу.\n",
    "3) Столбец education необходимо привести к общему виду (low case)\n",
    "4) Стобец dob_years (возраст клиента) имеет нулевые значения что так же не является отражением реальности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2. Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью применения связки методов isnull().any(axis=1) можем получить уникальную таблицу со всеми строками содержащими пропуски.\n",
    "\n",
    "Логика работы следующая: создаём логическую серию и использовать ее для индексации нашего датафрейма:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data[data.isnull().any(axis=1)] # отображение всех строчек содержащих NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Работа с NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим значения NaN в колонках days_employed и total_income на 0, т.к. отсутствие значений говорит нам о нулевом рабочем стаже заёмщика, а соответственно и о нулевом доходе. Количество отсутствующих записей совпадают\n",
    "\n",
    "В дальнейшем значения нулевые значения в total_income будут заменены на медиану для каждой категории граждан, которые будут выделены позже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['days_employed'].isnull().sum() # проверяем соответствие количество \n",
    "                                     # данных в обеих колонках, чтобы убедиться во взаимосвязи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['total_income'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['days_employed'] = data['days_employed'].fillna(0) # заменяем NaN на 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[data.isnull().any(axis=1)].sort_values('dob_years', ascending=True) #проверяем -> ждём пустую таюлицу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для большей правдивости данных заполним пустые значения в колонке total_income медианой для каждой из возрастных групп граждан"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замена пропусков в 'total_income'\n",
    "\n",
    "print(data['total_income'].isnull().sum()) # количество пропусков до цикла\n",
    " \n",
    "age_groups = [[0, 20], [21, 25] ,[26, 30], [31, 35], [36, 40], [41, 45], \n",
    "              [46, 50], [51, 55], [56, 60], [61, 65], [66, 70], [71, 74]]\n",
    "\n",
    "for group in age_groups:\n",
    "    \n",
    "    data.loc[(data['dob_years'] >= group[0]) & (data['dob_years'] <= group[1]) \\\n",
    "                    & (data['total_income'].isna() == True),'total_income'] \\\n",
    "    = data[(data['dob_years'] >= group[0]) \\\n",
    "                  & (data['dob_years'] <= group[1])]['total_income'].median()\n",
    "\n",
    " \n",
    "print(data['total_income'].isnull().sum()) # количество пропусков после цикла\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by='total_income') # визуальная оценка только что заполненных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "В данных отсутствовали 2174 значения о стаже работы и месячном доходе. Природа их появления слнедующая:  \n",
    "1) Клиенты действительно не работают и система автоматически пропускает значения total_income(месчного дохода) у безработных клиентов, т.к. кореляция между этими значениями 100%\n",
    "\n",
    "2) Клиенты не указывают место работы исходя из личных сообржений\n",
    "\n",
    "Данные ошибки в данных появились, вероятно, из-за смены формата записи их в базу данных\n",
    "\n",
    "Более связей по двум столбцам не найдено\n",
    "\n",
    "3) Имеется значение 0 в колонке dob_years(возраста клиентов), но т.к. это не имеет значение к поставленной задаче и принято решение оставить его нетронутым. Причина появляения - не указан возраст при подаче заявки\n",
    "\n",
    "Данная ошибка могла появиться из-за человеческого фактора, у клиентов была возможность не указывать свой возраст или же форма заполнения можно было перепутать с графой \"дата подачи заявки\". Нужно оповестить разработчиков что вероятнее всего или UX дизайнеров\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Замена типа данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "План:\n",
    "\n",
    "1) Испрвить значения стажа на абсолютные значения\n",
    "\n",
    "2) Привести столбец education к общему виду\n",
    "\n",
    "3) Перевести вещественные знаения в целочисленные\n",
    "\n",
    "4) Привести огромные значения в колонке days_employed к соответствующему виду, т.е. стаж в количество рабочих дней. Основная гипотеза - ошибка возникает потому что время приведено в часах, а не сутках.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# замена на абсолютные числа\n",
    "\n",
    "data['days_employed'] = abs(data['days_employed']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# перевод столбца education к общему виду\n",
    "\n",
    "data['education'] = data['education'].str.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head(10) # контроль"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приводим данные по колонки days_employed к коректным значениям, для этого я определил методом pd.df.describe() что огромный скачёк в значениях происходит в 4-м квантиле отсортированных по возрастанию значений колонки days_employed. это дало мне основание для того, чтобы выбрать значение 20000 как то, которое гарантированно будет отсукать корректные данные от некоректных.\n",
    "Далее, исходя из гипотезы что некоректные данные это часы, а не сутки я разделил значения на 24, чтобы часы соответствовали дням."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перевод некоректных значений рабочего стажа из часов в дни\n",
    "data.loc[data['days_employed'] > 20000, 'days_employed'] = data.loc[data['days_employed'] > 20000, 'days_employed'] / 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приводим вещественные колонки к целочисленному виду. Для изменения типа данных был выбран стандартный метод astype() т.к. метод to_numeric() приводит данные к типу floan64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# смена типа данных\n",
    "\n",
    "data[['days_employed', 'total_income']] = data[['days_employed', 'total_income']].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10) # визуальная проверка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных был ряд проблем: некоректные и отрицательные значения, разный формат заполнения строк в ячейках. Все проблемы были устранены и приведены в удобный для обработки вид"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum() # Определяем количество явных дупликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = data.drop_duplicates().reset_index(drop=True) # убираем все явные дупликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum() # проверяем количество дубликатов после чистки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дупликаты в данных могли появится по причинам: случайного совпадения, технической ошибки или рукописного ввода во время принятии заявки(человеческого фактора).\n",
    "\n",
    "Наша задача определить как один набор уникальных значений X влияет на конечный результат Y, это говорит нам о том, что дублирования одних и тех же наборов данных нам не интересно, так как результат этих данных уже будет известен. Поэтому мы можем свободно избавиться от дупликатов в данных. Метод сработал удачно и можем приступать к следующему этапу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # импортируем библиотеку sys для возможности установки сторонних библиотек\n",
    "!{sys.executable} -m pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem # импортируем pymystem3\n",
    "from collections import Counter # импортируем Counter для работы с лемматизацией\n",
    "m = Mystem() #назначаем переменную для комфортного взаимодействия с функцей\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_text = ' '.join(map(str, data['purpose'])) # с помощью функции map применяем метод str к пандасовской серии, \n",
    "                                                         # перевод каждого элемента в строку\n",
    "                                                         # join к каждому элементу в списке\n",
    "\n",
    "lemmas = m.lemmatize(list_to_text) #применяем лемматизацию\n",
    "\n",
    "print(Counter(lemmas)) # видим результат используя метод Counter для наглядности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы в локальной версии нужно было импортировать стандартную библиотеку пайтона для возможности загружать нестандартные библиотеки, какой и является pymystem3.\n",
    "\n",
    "После импорта всех необходимых библиотек и назначения технической переменной 'm' пришло время обрабатывать данные.\n",
    "Для начала нужно было перевести пандасовскую Серию в единую строку для последующей лемматизации.\n",
    "\n",
    "Применив к полученным данным метод Counter мы видим количества каждого применимого слова, это делает данные гораздо более однозначными. \n",
    "\n",
    "Людей больше всего интересует покупка недвижимости, второе место заняло кредитования для покупки автомобиля и на третьем месте получение образования, на четвёртом проведение свадьбы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Категоризация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для категоризации данных по цели покупки нам необходимо будет применить стемминг используя библиотеку nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer # импортируем из библиотеки nltk.stem нужный нам модуль\n",
    "nl = SnowballStemmer('russian') # назначаем тихническую переменную для работы с русским текстом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_of_purpose = list(data['purpose'].unique()) #Выделим все уникальные значения целей покупки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нам необходимо вычленить все категории. На первый взгляд их будет несколько: недвижимость, автомобиль, образование, здоровье, свадьба. Сейчас проверим это с помощью стемминга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stemmer_list = [] #пустой список для значений стемминга\n",
    "\n",
    "for item in list_of_purpose: # профодим стемминг по списку целей покупки\n",
    "        \n",
    "    for word in item.split(\" \"):\n",
    "        stemmer_list.append(nl.stem(word))\n",
    "        \n",
    "        \n",
    "sorted_stemmer_list = sorted(set(stemmer_list))\n",
    "print(sorted_stemmer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['purpose_category'] = np.nan # создаём пустую колонку для дальнейшего заполнения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Был выбрат способ np.nan, который заполняет весь столбец отсутствующими значениями. Был выбран этот метод по причине того, что на данном этапе у нас нет данных которыми мы готовы заполнить столбец\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как при лемминге гипотеза подтвердилась у нас имеются 4 освновных категории, вычленим уникальные значения из колонки data['purpose'] из категорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Выделяем списки для 4-х основных клиентских целей. \n",
    "# Для последующей категоризации\n",
    "\n",
    "estate_list = []\n",
    "car_list = []\n",
    "education_list = []\n",
    "wedding_list = []\n",
    "data['purpose_category'] = np.nan # создаём пустой столбец для дальнейшего заполнения\n",
    "\n",
    "for item in list_of_purpose: # разбиваем список всех возможных клиентских запросов на отдельные списки путём стемминга\n",
    "        \n",
    "    for word in item.split(\" \"):\n",
    "        \n",
    "        if nl.stem(word) == 'жил' or nl.stem(word) == 'недвижим':\n",
    "            estate_list.append(item) # заполняем список estate_list\n",
    "            \n",
    "        elif nl.stem(word) == 'автомобил' or nl.stem(word) == 'автомоб':\n",
    "            car_list.append(item) # заполняем список car_list\n",
    "            \n",
    "        elif nl.stem(word) == 'образован':\n",
    "            education_list.append(item) # заполняем список education_list\n",
    "            \n",
    "        elif nl.stem(word) == 'свадьб':\n",
    "            wedding_list.append(item) # заполняем список wedding_list\n",
    "\n",
    "for item in range(0, 21454): # присваиваем каждому значению в столбце purpose соответствующую ему категорию\n",
    "    \n",
    "    if data['purpose'][item] in estate_list:\n",
    "        data['purpose_category'][item] = 'недвижимость'\n",
    "                  \n",
    "    elif data['purpose'][item] in car_list:\n",
    "        data['purpose_category'][item] = 'автомобиль'\n",
    "                  \n",
    "    elif data['purpose'][item] in education_list:\n",
    "        data['purpose_category'][item] = 'образование'\n",
    "                  \n",
    "    elif data['purpose'][item] in wedding_list:\n",
    "        data['purpose_category'][item] = 'свадьба'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее нужно будет нарисовать таблицу в которой бы столбцы с целью были заменены на 4 категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.drop(labels='purpose', axis=1) # убираем лишний столбец, т.к. на его основе уже проведена категоризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['purpose_category'].unique() # проверяем коректно ли сработал код для присвоения категорий и нет ли там лишних значений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стемминговое исследование выделило 4 основных категории: недвижимость, автомобиль, образование, свадьба. Для выделения категории была составлена отдельная колонка data['purpose_category'] и заполнена в соответствии с клиентским запросом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 3. Ответьте на вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Есть ли зависимость между наличием детей и возвратом кредита в срок?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "children_debt_dict=data[['children','debt']] # выделим необходимые столбцы для анализа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В колонке ['children'] имеются отрицательные значения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. в столбце children есть отрицательные значения нужно использовать метод abs(). Этот метод вернёт абсолютное заначения каждого компонента столбца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children_debt_dict['children'] = children_debt_dict['children'].abs() # избавляемся от отрицательных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "children_debt_dict.groupby('children').agg({'debt': 'value_counts'}) # группируем любое количество детей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('процент клиентов без детей имеющих задолженость: {0:.0%}'.format((1063 / 13028)))\n",
    "print('процент клиентов с 1 ребёнком имеющих задолженость: {0:.0%}'.format((445 / 4410)))\n",
    "print('процент клиентов с 2 детьми имеющих задолженость: {0:.0%}'.format((194 / 1858)))\n",
    "print('процент клиентов с 3 детьми имеющих задолженость: {0:.0%}'.format((27 / 303)))\n",
    "print('процент клиентов с 4 детьми имеющих задолженость: {0:.0%}'.format((4 / 37)))\n",
    "print('процент клиентов с 5 детьми имеющих задолженость: {0:.0%}'.format((0 / 9)))\n",
    "print('процент клиентов с 20 детьми имеющих задолженость: {0:.0%}'.format((8 / 68)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я привёл данные тремя разными способами: сортировка датафрейма, группировка и сводная таблица. В данном случае самым удобным считаю метод groupby() за счёт длины кода и информативности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученные результаты говорят что самый высокий процент заделженности среди клиентов у тех, кто имеет по 20 детей, хотя скорее всего это ошибка в данных, но оставим как есть, следуя условиям задания, а самый низкий процент у клиентов имеющих 5 детей в семье.\n",
    "\n",
    "В среднем процент задолженности среди всех клиентов составляет 10% и не корелируется с количеством детей в семье"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Есть ли зависимость между семейным положением и возвратом кредита в срок?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "family_status_debt_dict=data[['family_status','debt']] # выделим необходимые столбцы для анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_status_debt_dict.sort_values(by='debt', ascending=False).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "family_status_debt_dict.groupby('family_status').agg({'debt': 'value_counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(family_status_debt_dict, values='debt', index='family_status', aggfunc=({'debt': ['value_counts']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('процент клиентов в статусе \"Не женат / не замужем\" имеющих задолженость: {0:.0%}'.format((274 / 2536)))\n",
    "print('процент клиентов в статусе \"в разводе\" имеющих задолженость: {0:.0%}'.format((85 / 1110)))\n",
    "print('процент клиентов в статусе \"вдовец / вдова\" имеющих задолженость: {0:.0%}'.format((63 / 896)))\n",
    "print('процент клиентов в статусе \"гражданский брак\" имеющих задолженость: {0:.0%}'.format((388 / 3763)))\n",
    "print('процент клиентов в статусе \"женат / замужем\" имеющих задолженость: {0:.0%}'.format((931 / 11408)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привёл данные тремя разными способами: сортировка датафрейма, группировка и сводная таблица. В данном случае самым удобным считаю метод groupby() за счёт длины кода и информативности.\n",
    "\n",
    "По данным можно сделать интересные выводы о том, не женатые/не замужные и состоящие в гражданском браке клиенты имеют больший процент задолженности чем остальные социальные группы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Есть ли зависимость между уровнем дохода и возвратом кредита в срок?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы коректно определить уровни дохода предлогаю использовать разделение на 3 класса, низший от 0 до 12792 (МРОТ), средний от 12792 до 120000 и высший от 120000 рублей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_income_debt_dict=data[['total_income','debt']] # выделим необходимые столбцы для анализа\n",
    "total_income_debt_dict['total_income_category'] = np.nan # создаём пустой столбец для дальнейшего присвоения категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for item in range(0, 21454): # цикл заполняющий столбец total_income_category относительно предложенных критериев\n",
    "    \n",
    "    if total_income_debt_dict['total_income'][item] <= 12792:\n",
    "        total_income_debt_dict['total_income_category'][item] = 'низший'\n",
    "                  \n",
    "    elif total_income_debt_dict['total_income'][item] > 12792 and total_income_debt_dict['total_income'][item] <= 120000:\n",
    "        total_income_debt_dict['total_income_category'][item] = 'средний'\n",
    "                  \n",
    "    elif total_income_debt_dict['total_income'][item] > 120000:\n",
    "        total_income_debt_dict['total_income_category'][item] = 'высший'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_income_debt_dict # проверяем коректность заполнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_income_debt_dict.groupby('total_income_category').agg({'debt': 'value_counts'}) # группируем данные для анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('процент клиентов среднего класса имеющих задолженость: {0:.0%}'.format((556 / 6347)))\n",
    "print('процент клиентов высшего класса имеющих задолженость: {0:.0%}'.format((1185 / 13366)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во время предобработки я заместил все отсутствующие значения в графе total_income на медианы для каждой возрастной группы, от этого в нашей таблице отсутствует низший класс, что в целом походит на реальность, т.к. клиенты с теми запросами, которые мы вывели при категоризации и с низким доходом не обращались бы в банк для заёма.\n",
    "\n",
    "На приведённой таблице мы видим что уровень дохода напрямую не влияет на результат и значения остаются в пределах 10% в любом варианте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Как разные цели кредита влияют на его возврат в срок?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purpose_category_debt_dict=data[['purpose_category','debt']] # выделим необходимые столбцы для анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "purpose_category_debt_dict.groupby('purpose_category').agg({'debt': 'value_counts'}) # группируем данные для анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('процент клиентов чья цель покупки автомобиль имели задолженость: {0:.0%}'.format((403 / 3903)))\n",
    "print('процент клиентов чья цель покупки недвижимость имели задолженость: {0:.0%}'.format((782 / 10029)))\n",
    "print('процент клиентов чья цель покупки образование имели задолженость: {0:.0%}'.format((370 / 3643)))\n",
    "print('процент клиентов чья цель покупки свадьба имели задолженость: {0:.0%}'.format((186 / 2138)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные показывают что самыми платежеспособными в данной метрике были клиенты обращающиеся в банк для покупки недвижимости и проведения свадьбы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 4. Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных было достаточно много грубых технических ошибок нуждающихся в предобработке. Данные ошибки влияли на результаты исследования и для точных расчётов нужно передать информацию специалисту по базе данных для устранения проблем.\n",
    "\n",
    "Иследуя данные по различным метрикам было выяснено что в среднем задолженость имеют 10% клиентов от общего числа обращений, а их показатели не корелируются с наличием задолжености.\n",
    "\n",
    "P.S. в ходе работ были использованы все полученные в спринте знания и ряд новых, до этого не представленных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист готовности проекта\n",
    "\n",
    "Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  открыт файл;\n",
    "- [x]  файл изучен;\n",
    "- [x]  определены пропущенные значения;\n",
    "- [x]  заполнены пропущенные значения;\n",
    "- [x]  есть пояснение, какие пропущенные значения обнаружены;\n",
    "- [x]  описаны возможные причины появления пропусков в данных;\n",
    "- [x]  объяснено, по какому принципу заполнены пропуски;\n",
    "- [x]  заменен вещественный тип данных на целочисленный;\n",
    "- [x]  есть пояснение, какой метод используется для изменения типа данных и почему;\n",
    "- [x]  удалены дубликаты;\n",
    "- [x]  есть пояснение, какой метод используется для поиска и удаления дубликатов;\n",
    "- [x]  описаны возможные причины появления дубликатов в данных;\n",
    "- [x]  выделены леммы в значениях столбца с целями получения кредита;\n",
    "- [x]  описан процесс лемматизации;\n",
    "- [x]  данные категоризированы;\n",
    "- [X]  есть объяснение принципа категоризации данных;\n",
    "- [x]  есть ответ на вопрос: \"Есть ли зависимость между наличием детей и возвратом кредита в срок?\";\n",
    "- [x]  есть ответ на вопрос: \"Есть ли зависимость между семейным положением и возвратом кредита в срок?\";\n",
    "- [x]  есть ответ на вопрос: \"Есть ли зависимость между уровнем дохода и возвратом кредита в срок?\";\n",
    "- [x]  есть ответ на вопрос: \"Как разные цели кредита влияют на его возврат в срок?\";\n",
    "- [x]  в каждом этапе есть выводы;\n",
    "- [x]  есть общий вывод."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Благодарю за ревью. Хорошего вам дня:3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
